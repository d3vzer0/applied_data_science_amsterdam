{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/logo_white_bkg_small.png\" align=\"right\" />\n",
    "\n",
    "#  Automate it All!\n",
    "This worksheet covers concepts relating to automating a machine learning model using the techniques we learned.  It should take no more than 20-30 minutes to complete.  Please raise your hand if you get stuck.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T15:21:16.151789Z",
     "start_time": "2019-02-27T15:21:16.145483Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Libraries - Make sure to run this cell!\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scikitplot as skplt\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import lime\n",
    "from tpot import TPOTClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step One:  Import the Data\n",
    "In this example, we're going to use the dataset we used in worksheet 5.3.  Run the following code to read in the data, extract the features and target vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T04:55:31.723676Z",
     "start_time": "2019-02-27T04:55:31.708177Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/dga_features_final_df.csv')\n",
    "target = df_final['isDGA']\n",
    "feature_matrix = df_final.drop(['isDGA'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, perform the test/train split in the conventional manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T15:28:07.887489Z",
     "start_time": "2019-02-27T15:28:07.885031Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Two:  Run the Optimizer\n",
    "In the next step, use TPOT to create a classification pipeline using the DGA data set that we have been using.  The `TPOTClassifier()` has many configuration options and in the interest of time, please set the following variables when you instantiate the classifier.\n",
    "\n",
    "* `max_eval_time_mins`:  In the interests of time, set this to 15 or 20.\n",
    "* `verbosity`: Set to 1 or 2 so you can see what TPOT is doing.\n",
    "\n",
    "\n",
    "**Note:  This step will take some time, so you might want to get some coffee or a snack when it is running.**  While this is running take a look at the other configuration options available here: http://epistasislab.github.io/tpot/api/.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T06:03:30.680093Z",
     "start_time": "2019-02-27T04:59:00.937173Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here... \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Three:  Evaluate the Performance\n",
    "Now that you have a trained model, the next step is to evaluate the performance and see how TPOT did in comparison with earlier models we created.  Use the techniques you've learned to evaluate the performance of your model.  Specifically, print out the `classification report` and a confusion matrix. \n",
    "\n",
    "Unfortunately, Yellowbrick will not work in this instance, however, you can generate a similar visual confusion matrix with the following code:\n",
    "\n",
    "```\n",
    "import scikitplot as skplt\n",
    "skplt.metrics.confusion_matrix(optimized_preds, target_test)\n",
    "\n",
    "```\n",
    "\n",
    "What is the accuracy of your model?  Is it significantly better than what you did in earlier labs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T15:21:37.710556Z",
     "start_time": "2019-02-27T15:21:37.700287Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here...\n",
    "\n",
    "# Output the classification report\n",
    "\n",
    "# Render the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4:  Export your Pipeline\n",
    "If you are happy with the results from `TPOT` you can export the pipeline as python code. The final step in this lab is to export the pipeline as a file called `automate_ml.py` and examine it.  What model and preprocessing steps t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here... \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
