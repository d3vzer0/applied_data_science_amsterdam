{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/logo_white_bkg_small.png\" align=\"right\" />\n",
    "\n",
    "# Worksheet 2.1:  Working with Two Dimensional Data\n",
    "This worksheet covers concepts covered in Module 2 - Exploratory Data Analysis in Two Dimensions.  It should take no more than 20-30 minutes to complete.  Please raise your hand if you get stuck.  \n",
    "\n",
    "There are many ways to accomplish the tasks that you are presented with, however you will find that by using the techniques covered in class, the exercises should be relatively simple. \n",
    "\n",
    "## Import the Libraries\n",
    "For this exercise, we will be using:\n",
    "* Pandas (http://pandas.pydata.org/pandas-docs/stable/)\n",
    "* Numpy (https://docs.scipy.org/doc/numpy/reference/)\n",
    "* Matplotlib (http://matplotlib.org/api/pyplot_api.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "plt.style.use('ggplot')\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Reading various forms of JSON Data\n",
    "In the `/data/` folder, you will find a series of `.json` files called `dataN.json`, numbered 1-4.  Each file contains the following data:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th></th>\n",
    "        <th>birthday</th>\n",
    "        <th>first_name</th>\n",
    "        <th>last_name</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>0</td>\n",
    "        <td>5\\/3\\/67</td>\n",
    "        <td>Robert</td>\n",
    "        <td>Hernandez</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>1</td>\n",
    "        <td>8\\/4\\/84</td>\n",
    "        <td>Steve</td>\n",
    "        <td>Smith</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>2</td>\n",
    "        <td>9\\/13\\/91</td>\n",
    "        <td>Anne</td>\n",
    "        <td>Raps</td>\n",
    "    </tr>    \n",
    "    <tr>\n",
    "        <td>3</td>\n",
    "        <td>4\\/15\\/75</td>\n",
    "        <td>Alice</td>\n",
    "        <td>Muller</td>\n",
    "    </tr>    \n",
    "</table>\n",
    "\n",
    "Using the `.read_json()` function and the various configuration options, read all these files into a dataframe.  The documentation is available here: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_json.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_HOME = '../data/'\n",
    "# DATA_HOME + 'data1.json' # this gives you the filename\n",
    "\n",
    "### YOUR CODE ###\n",
    "# df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE ###\n",
    "# df2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE ###\n",
    "# df3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE ###\n",
    "# df4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: \n",
    "In the data file, there is a webserver file called `hackers-access.httpd`.  For this exercise, you will use this file to answer the following questions:\n",
    "1.  Which browsers are the top 10 most used browsers in this data?\n",
    "2.  Which are the top 10 most used operating systems?\n",
    "\n",
    "In order to accomplish this task, do the following:\n",
    "1.  Write a function which takes a User Agent string as an argument and returns the relevant data.  HINT:  You might want to use python's `user_agents` module, the documentation for which is available here: (https://pypi.python.org/pypi/user-agents)\n",
    "2.  Next, apply this function to the column which contains the user agent string.\n",
    "3.  Store this series as a new column in the dataframe\n",
    "4.  Count the occurances of each value in the new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import apache_log_parser\n",
    "from user_agents import parse\n",
    "#Read in the log file\n",
    "line_parser = apache_log_parser.make_parser(\"%h %l %u %t \\\"%r\\\" %>s %b \\\"%{Referer}i\\\" \\\"%{User-agent}i\\\"\")\n",
    "\n",
    "### YOUR CODE ###\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write the functions\n",
    "\n",
    "\n",
    "### YOUR CODE ###\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Apply the functions to the dataframe\n",
    "\n",
    "\n",
    "### YOUR CODE ###\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the top 10 values\n",
    "\n",
    "### YOUR CODE ###\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3:\n",
    "Using the `dailybots.csv` film, read the file into a DataFrame and perform the following operations:\n",
    "1.  Filter the DataFrame to include bots from the Government/Politics Industry.\n",
    "2.  Calculate the ratio of hosts to orgs and add this as a column to the DataFrame and output the result\n",
    "3.  Calculate the total number of hosts infected by each BotFam in the Government/Politics Industry.  You should use the `groupby()` function which is documented here: (http://pandas.pydata.org/pandas-docs/stable/groupby.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### YOUR CODE ###\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### YOUR CODE ###\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE ###\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise 4:\n",
    "\n",
    "Read a more ```evil``` JSON ```eve_small.json```, where each line contains a nested JSON object. Derive one DataFrame, where all levels for the ```stats``` key are expanded to a top level column of that DataFrame. Easiest is to natively open the file in Python, loop over each line, use [json.loads](https://docs.python.org/3.5/library/json.html) from the json library, and then [json_normalize](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.io.json.json_normalize.html) to expand the nested structure to top-level columns, append to a simple Python list and finally call [pd.concat](http://pandas.pydata.org/pandas-docs/version/0.20/generated/pandas.concat.html) on the list to get one complete DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nested_json_to_df(fname_str):\n",
    "    ### YOUR CODE ###\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return result ### YOUR CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#eve = nested_json_to_df(DATA_HOME + 'eve_small.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE ###\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise 5\n",
    "In this exercise, you will learn how to convert a PCAP file into JSON and do some basic summarization of the data.  In the `data` directory, you will find a file called `http.pcap`.  Our first step is to convert this to JSON.  To do this we have installed a python module called `pcapview` (docs available here: https://pydigger.com/pypi/pcapview) which can convert the pcap file to JSON.  \n",
    "\n",
    "Once you've done that, your assignment is to answer the following questions:\n",
    "1.  What are the most frequent source IP addresses?\n",
    "2.  How many differnet source ports were accessed?\n",
    "\n",
    "To do this you will have to load this data into a DataFrame.  Using what we've learned in class, do the following:\n",
    "1.  Load the data into a DataFrame using the technique of your choice\n",
    "2.  Extract the requisite columns from the DataFrame, in this case, you want the source IP and source ports\n",
    "3.  Execute a `value_counts()` on those columns.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "### YOUR CODE ###\n",
    "\n",
    "\n",
    "\n",
    "#Normalize it and load it into a DataFrame\n",
    "\n",
    "\n",
    "### YOUR CODE ###\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the source port and count the unique values\n",
    "### YOUR CODE ###\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the source IP and count the unique values\n",
    "\n",
    "### YOUR CODE ###\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
